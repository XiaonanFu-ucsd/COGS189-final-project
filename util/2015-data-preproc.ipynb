{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                      \n",
    "import matplotlib.pyplot as plt                         \n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import scipy.signal as signal \n",
    "from scipy.io import loadmat\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our filter variables\n",
    "fs = 512                      # Hz; sampling rate\n",
    "dt = 1000. / fs                 # ms; time between samples\n",
    "sdt = dt#np.round(dt).astype(int); # rounded dt so that we can index samples\n",
    "hp = 1                        # Hz; our low cut for our bandpass\n",
    "lp = 24.                        # Hz; our high cut for our bandpass\n",
    "num_taps = 31                   # Number of taps/coefficients of FIR filter\n",
    "\n",
    "# Create our filter coefficients\n",
    "# Note: by defining 'fs' we don't divide our windows by the Nyquist\n",
    "# Note: for FIR filters, a is always 1\n",
    "b = signal.firwin(numtaps=num_taps, cutoff=[hp, lp], pass_zero='bandpass', fs=fs)\n",
    "a = 1\n",
    "\n",
    "# Define ERP-related variables\n",
    "epoch_start = 0    # ms\n",
    "epoch_end = 800    # ms\n",
    "baseline_start = 0 # ms\n",
    "baseline_end = 100 # ms\n",
    "erp_start = 200    # ms\n",
    "erp_end = 800      # ms\n",
    "\n",
    "# Let's translate these from time into index space to save time later\n",
    "e_s = np.round(epoch_start / sdt).astype(int)     # epoch start\n",
    "e_e = np.round(epoch_end / sdt).astype(int)       # epoch end\n",
    "bl_s = np.round(baseline_start / sdt).astype(int) # baseline start\n",
    "bl_e = np.round(baseline_end / sdt).astype(int)   # baseline end\n",
    "erp_s = np.round(erp_start / sdt).astype(int)     # ERP component window start\n",
    "erp_e = np.round(erp_end / sdt).astype(int)       # ERP component window end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util as myUtil\n",
    "def load_file_from_bi2015a(filename):\n",
    "    headerNames = pd.read_csv('./datasets/bi2015a/Header.csv', header=None)\n",
    "    headerNames = np.array(headerNames.iloc[0]).flatten()\n",
    "    if not Path(filename).exists():\n",
    "        raise ValueError(\"File does not exist   \" + filename)\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    df.columns = headerNames\n",
    "    del headerNames\n",
    "    #timestamps = df['Time'].values\n",
    "    sample_rate = 512\n",
    "    x = df.iloc[:, 1:33].values\n",
    "    df = df.iloc[:, -2:]\n",
    "    df['y'] = 0\n",
    "    df.loc[df['Trigger'] == 1, 'y'] = -1\n",
    "    df.loc[df['Target'] == 1, 'y'] = 1\n",
    "    y = df.y.values\n",
    "    del df\n",
    "    # x = myUtil.resample_x(x, rate=sample_rate, target_rate=fs)\n",
    "    # y = myUtil.resample_y(y, rate=sample_rate, target_rate=fs)\n",
    "    x = x.T\n",
    "    x = signal.filtfilt(b, a, x, axis=1)\n",
    "    x = x[:, 2*fs:]\n",
    "    y = y[2*fs:]\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 1 (4956, 32, 410) (4956,)\n",
      "subject 2 (1512, 32, 410) (1512,)\n",
      "subject 3 (1044, 32, 410) (1044,)\n",
      "subject 4 (1440, 32, 410) (1440,)\n",
      "subject 5 (1188, 32, 410) (1188,)\n",
      "subject 6 (1584, 32, 410) (1584,)\n",
      "subject 7 (1224, 32, 410) (1224,)\n",
      "subject 8 (1512, 32, 410) (1512,)\n",
      "subject 9 (1332, 32, 410) (1332,)\n",
      "subject 10 (1116, 32, 410) (1116,)\n",
      "subject 11 (1440, 32, 410) (1440,)\n",
      "subject 12 (2232, 32, 410) (2232,)\n",
      "subject 13 (1368, 32, 410) (1368,)\n",
      "subject 14 (1404, 32, 410) (1404,)\n",
      "subject 15 (1260, 32, 410) (1260,)\n",
      "subject 16 (1260, 32, 410) (1260,)\n",
      "subject 17 (1620, 32, 410) (1620,)\n",
      "subject 18 (1620, 32, 410) (1620,)\n",
      "subject 19 (1800, 32, 410) (1800,)\n",
      "subject 20 (1620, 32, 410) (1620,)\n",
      "subject 21 (1260, 32, 410) (1260,)\n",
      "subject 22 (1584, 32, 410) (1584,)\n",
      "subject 23 (1368, 32, 410) (1368,)\n",
      "subject 24 (1296, 32, 410) (1296,)\n",
      "subject 25 (2088, 32, 410) (2088,)\n",
      "subject 26 (1116, 32, 410) (1116,)\n",
      "subject 27 (2844, 32, 410) (2844,)\n",
      "subject 28 (1800, 32, 410) (1800,)\n",
      "subject 29 (1836, 32, 410) (1836,)\n",
      "subject 30 (972, 32, 410) (972,)\n",
      "subject 31 (2700, 32, 410) (2700,)\n",
      "subject 32 (1116, 32, 410) (1116,)\n",
      "subject 33 (1512, 32, 410) (1512,)\n",
      "subject 34 (1260, 32, 410) (1260,)\n",
      "subject 35 (2484, 32, 410) (2484,)\n",
      "subject 36 (1440, 32, 410) (1440,)\n",
      "subject 37 (2520, 32, 410) (2520,)\n",
      "subject 38 (1332, 32, 410) (1332,)\n",
      "subject 39 (1764, 32, 410) (1764,)\n",
      "subject 40 (1944, 32, 410) (1944,)\n",
      "subject 41 (1620, 32, 410) (1620,)\n",
      "subject 42 (2052, 32, 410) (2052,)\n",
      "subject 43 (1044, 32, 410) (1044,)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "subject = range(1,44)\n",
    "session = [1, 2, 3]\n",
    "X_train = None\n",
    "y_train = np.array([])\n",
    "out_dir = \"./datasets/2015pre/\"\n",
    "for i in subject:\n",
    "    for j in session:\n",
    "        x, y = load_file_from_bi2015a(f'./datasets/bi2015a/subject_{i:02}_session_{j:02}.csv')\n",
    "        x, y = myUtil.epoch_wrt_event_chanFirst(x, y, e_s, e_e)\n",
    "        X_train = np.concatenate((X_train, x)) if X_train is not None else x\n",
    "        y_train = np.concatenate((y_train, y))\n",
    "    print(f\"subject {i}\", X_train.shape, y_train.shape)\n",
    "    \n",
    "    with open(out_dir + f\"x{i}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(X_train, f)\n",
    "    with open(out_dir + f\"y{i}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(y_train, f)\n",
    "    X_train = None\n",
    "    y_train = np.array([])\n",
    "        \n",
    "\n",
    "# print(X_train.shape, y_train.shape)\n",
    "\n",
    "# linesI_no_nan = np.where(np.isnan(X_train).any(axis=1).any(axis=1) == False)[0]\n",
    "# X_train = X_train[linesI_no_nan]\n",
    "# y_train = y_train[linesI_no_nan]\n",
    "\n",
    "# print(X_train.shape, y_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
